---
title: "data-cleaning"
author: "Baron Curtin"
date: "March 22, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
lapply(c("tidyverse", "magrittr", "RCurl", "XML", "kableExtra"), require, character.only=TRUE)
```

## Load Dataset
```{r load-data}
plainText <- getURL("https://raw.githubusercontent.com/baroncurtin2/data607-project3/master/data/cleanjobfiles.txt") %>%
  read_lines %>%
  paste(collapse = " ")

searchTerms <- getURL("https://raw.githubusercontent.com/baroncurtin2/data607-project3/master/data/searchterms.csv") %>%
  read_csv(col_names = FALSE, trim_ws = TRUE) %>%
  # convert to vector
  pull(1)

# helper function
returnZero <- function(x) 0

# create empty data frame
termsDf <- data.frame(matrix(nrow = 300, ncol = length(searchTerms)))
# give dataframe column names
colnames(termsDf) <- searchTerms
# mutate rows so they are all the column name
termsDf %<>%
  mutate_all(funs(returnZero(.)))
```

## Convert Massive Text String to Vector to Data Frame
  * The objective here is to attempt to create a "regular" dataset
  * Key characteristics will be one job posting per row

```{r convert}
jobPostings <- plainText %>%
  # extract all instances of span tag
  str_extract_all('(<span id=(.*?)>)(.*?)(</span>)') %>%
  # unnest the list
  unlist %>%
  # convert to data frame
  data_frame(jobPost = .)
```


## Tidy the Data
  * The key objective here is to break up the singular column into multiple columns
```{r tidy}
# helper function

separateCols <- jobPostings %>%
  # separate jobPost column into the "summary" and "requirements" of role
  separate(col=jobPost, into=c("summary", "requirements"), sep="<ul>|<li>", extra = "merge", fill="right")

# add search term columns
separateCols <- cbind(separateCols, termsDf)  

# dataset for non-NA
nonNA <- separateCols %>%
  # filter for non-NA
  filter(!is.na(requirements))
  #mutate_at(vars(ruby:visualization), funs())

# get counts of keywords
for(i in 3:ncol(nonNA)) {
  nonNA[, i] <- str_count(nonNA$requirements, colnames(nonNA)[i])
}

# dataset for NA
dataNA <- separateCols %>%
  # filter for non-NA
  filter(is.na(requirements))

# get counts of keywords
for(i in 3:ncol(dataNA)) {
  dataNA[, i] <- str_count(dataNA$summary, colnames(dataNA)[i])
}
```
  
  
  
## Generate CSV File
```{r write-csv}
# bind rows of NA and nonNA
jobPostings <- bind_rows(nonNA, dataNA)

# show table
knitr::kable(head(jobPostings, 10), "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

# write csv
write_csv(jobPostings, "./data/jobpostings.csv")
```

